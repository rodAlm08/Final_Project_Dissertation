@misc{doshivelez2017rigorous,
      title={Towards A Rigorous Science of Interpretable Machine Learning}, 
      author={Finale Doshi-Velez and Been Kim},
      year={2017},
      eprint={1702.08608},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
},
@misc{angular-components,
    key = {https://angular.io/api/core/Component},
    note = {Angular Components}

},

@misc{angular-modules,
    key = {https://angular.io/guide/architecture-modules},
    note = {Angular Modules}

},
@misc{angular-services,
    key = {https://angular.io/guide/architecture-services#introduction-to-services-and-dependency-injection},
    note = {Angular Services}

},

@misc{apache_spark,
    key = {https://spark.apache.org/docs/latest/ml-classification-regression.html},
    note = {Apache Spark, Accessed: 14 October 2023},
    howpublished =  {\url{https://spark.apache.org/docs/latest/ml-classification-regression.html}}
}

@INPROCEEDINGS{tensor_flow,
  author={Heaton, Jeff and McElwee, Steven and Fraley, James and Cannady, James},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Early stabilizing feature importance for TensorFlow deep neural networks}, 
  year={2017},
  volume={},
  number={},
  pages={4618-4624},
  doi={10.1109/IJCNN.2017.7966442}}

@article{spark,
  title={Mllib: Machine learning in apache spark},
  author={Meng, Xiangrui and Bradley, Joseph and Yavuz, Burak and Sparks, Evan and Venkataraman, Shivaram and Liu, Davies and Freeman, Jeremy and Tsai, DB and Amde, Manish and Owen, Sean and others},
  journal={The journal of machine learning research},
  volume={17},
  number={1},
  pages={1235--1241},
  year={2016},
  publisher={JMLR. org}
}

@article{salloum2016big,
  title={Big data analytics on Apache Spark},
  author={Salloum, Salman and Dautov, Ruslan and Chen, Xiaojun and Peng, Patrick Xiaogang and Huang, Joshua Zhexue},
  journal={International Journal of Data Science and Analytics},
  volume={1},
  pages={145--164},
  year={2016},
  publisher={Springer}
}

@misc{meng2015mllib,
      title={MLlib: Machine Learning in Apache Spark}, 
      author={Xiangrui Meng and Joseph Bradley and Burak Yavuz and Evan Sparks and Shivaram Venkataraman and Davies Liu and Jeremy Freeman and DB Tsai and Manish Amde and Sean Owen and Doris Xin and Reynold Xin and Michael J. Franklin and Reza Zadeh and Matei Zaharia and Ameet Talwalkar},
      year={2015},
      eprint={1505.06807},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Spark_SQL,
author = {Armbrust, Michael and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J. and Ghodsi, Ali and Zaharia, Matei},
title = {Spark SQL: Relational Data Processing in Spark},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723372.2742797},
doi = {10.1145/2723372.2742797},
abstract = {Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.},
booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
pages = {1383–1394},
numpages = {12},
keywords = {spark, machine learning, databases, data warehouse, hadoop},
location = {Melbourne, Victoria, Australia},
series = {SIGMOD '15}
}

@article{bigdata,
    author = {},
    title = "{News}",
    journal = {Significance},
    volume = {9},
    number = {4},
    pages = {2-3},
    year = {2012},
    month = {08},
    issn = {1740-9705},
    doi = {10.1111/j.1740-9713.2012.00582.x},
    url = {https://doi.org/10.1111/j.1740-9713.2012.00582.x},
    eprint = {https://academic.oup.com/jrssig/article-pdf/9/4/2/49111484/sign\_9\_4\_2.pdf},
}

@article{hadoop,
title = {A comprehensive view of Hadoop research—A systematic literature review},
journal = {Journal of Network and Computer Applications},
volume = {46},
pages = {1-25},
year = {2014},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2014.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S1084804514001635},
author = {Ivanilton Polato and Reginaldo Ré and Alfredo Goldman and Fabio Kon},
keywords = {Systematic literature review, Apache Hadoop, MapReduce, HDFS, Survey}
}

@article{apache-spark,
  title={Big data analytics on Apache Spark},
  author={Salloum, Salman and Dautov, Ruslan and Chen, Xiaojun and Peng, Patrick Xiaogang and Huang, Joshua Zhexue},
  journal={International Journal of Data Science and Analytics},
  volume={1},
  pages={145--164},
  year={2016},
  publisher={Springer}
}

@INPROCEEDINGS{8988541,
  author={Shaikh, Eman and Mohiuddin, Iman and Alufaisan, Yasmeen and Nahvi, Irum},
  booktitle={2019 2nd IEEE Middle East and North Africa COMMunications Conference (MENACOMM)}, 
  title={Apache Spark: A Big Data Processing Engine}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/MENACOMM46666.2019.8988541}}